name: Build sites_context.txt

on:
  workflow_dispatch:
  schedule:
    - cron: "0 6 * * *"  # di√°rio 06:00 UTC

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 readability-lxml trafilatura

      - name: Crawl and build context
        run: |
          python << 'PY'
          import trafilatura, sys, pathlib, datetime, requests
          SEED = [
            "https://www.affix.com.br/",
            "https://www.affix.com.br/manuais/",
            "https://www.hapvida.com.br/",
            "https://www.alterbeneficios.com.br/"
          ]
          texts = []
          for url in SEED:
            try:
              downloaded = trafilatura.fetch_url(url, no_fallback=False)
              if not downloaded: continue
              text = trafilatura.extract(downloaded, include_comments=False, include_tables=False)
              if text:
                texts.append(f"[URL]: {url}\n[EXTRACT]:\n{text}\n---\n")
            except Exception as e:
              pass
          out = "\n".join(texts)
          p = pathlib.Path("sites_context.txt")
          p.write_text(out, encoding="utf-8")
          print(f"Wrote {p} with {len(out)} chars at {datetime.datetime.utcnow().isoformat()}Z")
          PY

      - name: Commit changes
        run: |
          git config user.name "crion-bot"
          git config user.email "crion-bot@users.noreply.github.com"
          git add sites_context.txt
          git commit -m "build: update sites_context.txt" || echo "no changes"
          git push
